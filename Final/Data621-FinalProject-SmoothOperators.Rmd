---
title: "DATA621-FinalProject-SmoothOperators"
author: "Rob Hodde, Matt Farris, Jeffrey Burmood, Bin Lin"
date: "5/26/2017"
output: pdf_document
---

\begin{center}
{\huge Introduction}
\end{center}

##Abstract 

*Movies:* The quintessential form of storytelling that we as humans, have developed thus far.  Movies have become the modern past-time for us, a way to escape the humdrum of everyday life into a fantasy world filled with drama, intrigue and delight. Movies have astounded audiences for the best part of a century, and with that, movie making has become a vast and lucrative industry.  Studios, actors and actresses, directors, and production companies make up just a small part of world of film, and we hope by looking into some movie data we will be able to find some insights into that world. Finally, as avid fans and lovers of all films, we hope this report will both entertain you and reveal new insights into a fascinating world.


##Problem Description  
  
In this project, we explore, analyze and model a dataset containing information on approximately 5,000 movies. The dataset contains movie data extracted from the IMDB website and is available on Kaggle.com.

We develop predictive models for three questions:  
  
1) Will the movie make money or lose money?  
  
2) What is the anticipated gross margin (profit) for the movie?

3) Do any particular movie content keywords influence profitability?


\begin{center}
{\huge Data Exploration}
\end{center}
  
##Data Exploration

The first part of our project consists of exploring our data source. As stated above, it came from Kaggle, a repository/social hub for data analysts like ourselves.  Obviously the dataset isn't complete, since thousands of movies are released each year.

  
```{r,echo=FALSE}
# Load required libraries

suppressWarnings(suppressMessages(library(ggplot2)))
suppressWarnings(suppressMessages(library(ROCR)))
suppressWarnings(suppressMessages(library(RCurl)))
suppressWarnings(suppressMessages(library(knitr)))
suppressWarnings(suppressMessages(library(Hmisc)))
suppressWarnings(suppressMessages(library(caret)))
suppressWarnings(suppressMessages(library(stringr)))
suppressWarnings(suppressMessages(library(mice)))
suppressWarnings(suppressMessages(library(dplyr)))
suppressWarnings(suppressMessages(library(reshape2)))
suppressWarnings(suppressMessages(library(MASS)))
suppressWarnings(suppressMessages(library(pscl)))
suppressWarnings(suppressMessages(library(broom)))
suppressWarnings(suppressMessages(library(lmtest)))
suppressWarnings(suppressMessages(library(moments)))
suppressWarnings(suppressMessages(library(forecast)))
suppressWarnings(suppressMessages(library(data.table)))


# Read in the dataset from github
movies.raw <- read.csv(text=getURL("https://raw.githubusercontent.com/jeffreyburmood/data621/master/Final/movie_metadata.csv"),header=TRUE,na.strings=c(""," "), stringsAsFactors = FALSE)

cpi <- read.csv(text=getURL("https://raw.githubusercontent.com/jeffreyburmood/data621/master/Final/CPI-Year.csv"),header=TRUE,na.strings=c(""," "), stringsAsFactors = FALSE)
names(cpi)<-c("title_year","cpi")

# Remove the columns not being used in the analysis
col.remove <- c(1,2,3,7,10,11,15,17,18,19,20,27,28)
movies <- subset(movies.raw,select=-col.remove)

# there are only a few NAs, go ahead and remove rows with NAs
movies <- na.omit(movies)

#Remove's Unicode Error for PDF Latex
movies$movie_title <- iconv(movies$movie_title, "latin1", "ASCII", sub="")

#Removing Foreign Films
movies <-subset(movies, country == "USA")
movies <- subset(movies, select = -country)
```
  
First we remove the data columns for the variables that we will not be using in the analysis.  We focus on the following variables:  
  
```{r,echo=FALSE}
names(movies)
```
  
After exploring the data, we notice there is a scattering of NAs across the variables. Due to the relatively low number of total NAs, we remove all rows with NAs, leaving 3,828 rows of data. 

Furthermore, we notice approximately 800 foreign films. Though we would love for these to be part of our dataset, the production budget and gross receipts variables for these films tend to differ dramatically.  The budget is usually in the currency of the home country whereas the gross receipts tend to be in U.S. dollars.  Because of the unwieldiness of adjusting for multiple currency exchange rates across many years on a case-by-case basis, we must remove this data.  This leaves us with 3042 movies to analyze, which we feel is more than adequate for the project. 
  
Next we explore the nature of the data for the variables to be used in the analysis.  
  
```{r,echo=FALSE,fig.width = 8, fig.height = 3}
# Let's start by exploring the type of each variable
types <- sapply(1:length(movies),function(x) typeof(movies[,x]))
types.df <- data.frame(VAR=names(movies),TYPE=types)
kable(types.df)

# Set up content rating as factors to form a categorical variable for modeling
movies$content_rating <- factor(movies$content_rating)

# Show a statistical summary of the data
kable(summary(movies[,1:5]))
kable(summary(movies[,6:10]))
kable(summary(movies[,11:14]))
```


We investigate correlations. Below, we can see that none of the variables have significant correlation that we can perceive.  


```{r,echo=FALSE,fig.width = 8, fig.height = 3}
# grab just the numeric data columns for variable analysis
movies.numeric <- subset(movies,select=-c(6,10))

# start by looking for correlations between the numeric variables (ONLY the predictor variables)
movies.pred <- subset(movies.numeric, select=-c(5))
cor.table <- cor(movies.pred) # build a table of inter-variable correlation values
kable(cor.table[,1:4])
kable(cor.table[,5:8])
kable(cor.table[,9:10])
```



Lastly for exploration, we examine all variables using boxplots, histograms, and scatter plots.  


```{r,echo=FALSE,fig.width = 8, fig.height = 3}
# Look at the boxplots of the numeric variables
f <- colnames(movies.numeric)  # establish the data categories to be studied
par(mfrow=c(1,3))

for (i in 1:length(f)){
  boxplot(movies.numeric[,i],main = f[i])
}

# we also need to look at the histograms for the numeric variables
for (i in 1:length(f)){
  m <- mean(movies.numeric[,i])
  s <- sd(movies.numeric[,i])  
  hist(movies.numeric[,i],freq=FALSE,main = f[i],xlab="")
  curve(dnorm(x,mean=m,sd=s),col="darkblue",lwd=2,add=TRUE)
}

# let's also look at a quick plot of the data for each variable
for (i in 1:length(f)){
  plot(movies.numeric[,i],main = f[i],xlab="",ylab="")
}
```
  
As we can see from the plots and statistical summaries above, most of the variables are nearly normally distributed except those variables associated with Facebook Likes.  There are five variables related to Facebook Likes that are highly skewed due to a large number of zeros.  An examination of the dataset source reveals that the "zero" values from the Facebook Likes were caused by simple errors in Web page scraping.  At this point we assume these zeros represent NAs in the Facebook data, and we use the MICE package to impute the Facebook Likes data for the zeros/NAs.
  

```{r,echo=FALSE}
# build a dataframe of just the Facebook Likes data
facebook.likes <- data.frame(director_facebook_likes=movies$director_facebook_likes,actor_1_facebook_likes=movies$actor_1_facebook_likes,actor_2_facebook_likes=movies$actor_2_facebook_likes,actor_3_facebook_likes=movies$actor_3_facebook_likes,cast_total_facebook_likes=movies$cast_total_facebook_likes)
# now convert all of the zero values to "NA"
facebook.likes <- sapply(facebook.likes, function(x) ifelse(x==0,NA,x))
# review the NA patterns for each variable
md.pattern(facebook.likes)
#mice PACKAGE
#uses Predictive Mean Matching. 
fb.likes.i <- mice(facebook.likes, m = 3, print=F)
facebook.likes <- complete(fb.likes.i,1)
# repopulate the movies dataframe with the imputed variable
movies$director_facebook_likes <- facebook.likes$director_facebook_likes
movies$actor_1_facebook_likes <- facebook.likes$actor_1_facebook_likes
movies$actor_2_facebook_likes <- facebook.likes$actor_2_facebook_likes
movies$actor_3_facebook_likes <- facebook.likes$actor_3_facebook_likes
movies$cast_total_facebook_likes <- facebook.likes$cast_total_facebook_likes

summary(movies)
```


\begin{center}
{\huge Data Preparation}
\end{center}


##Data Preparation  

One of the big issues with using this dataset is the time-frame. These movies were released over the past 80+ years. The following histogram shows the distribution of movies released by year.  


```{r,echo=FALSE}
hist(movies$title_year,main = "Year Released",xlab="")
```
  

As you can see, the vast majority come from the 1990's and later, but we don't want to ignore the movies from previous years.  In order to accurately portray data values from the more distant past, we institute a rate of inflation calculation.  Using the Consumer Price Index released by the U.S. Bureau of Labor Statistics, we calculate the adjusted production budget and gross receipts values by year. As a basis of comparison, we use the CPI from 2016, since the last movie was released in 2016. 


```{r,echo=FALSE}
movies <- merge(x = movies, y = cpi, by = "title_year")
movies$adj_gross <- with(movies, (240/cpi * gross))
movies$adj_budget <- with(movies, (240/cpi * budget))
movies$adj_margin <- with(movies, adj_gross-adj_budget)
```

```{r,echo=FALSE,fig.width = 8, fig.height = 4}
attach(movies)
#par(mfrow=c(2,1))
plot(title_year,gross, main="Unadjusted Gross Per Year")
plot(title_year,adj_gross,main="Adjusted Gross Per Year")
```

From the above scatter plots, we can see that the adjustment for inflation does indeed create a more realistic picture of overall movie business revenues.  (U.S. movie ticket buys peaked around 1940 and have been shrinking ever since.)  

As a point of interest, the movies that made over one billion dollars (U.S. receipts only, adjusted) are shown below:


```{r,echo=FALSE}
highest_gross <- subset(movies, adj_gross > 1000000000, select=c("movie_title", "gross", "adj_gross"))
highest_gross
```

A quick Google search indicates that the above movies are consistently listed as the top grossing movies of all time. Furthermore, our "estimated adjusted gross" mimics the findings that we see with adjusted gross (for the most part, there are two schools of thought on how to adjust gross, using ticket prices or our method adjusting based on CPI). Though our dollar amounts vary slightly from other sources, any variance is consistent across our dataset, and would not negatively impact the overall results.   

```{r,echo=FALSE}
#boxplot(movies$adj_margin, main ="Profit Margin")  #Rob commented, not sure of context
```


\begin{center}
{\huge Build Models}
\end{center}
##Build Models  

### Binomial Regression 

In our first model we investigate whether or not we can predict if a film will make a profit, given the cast and direction.  To do this, we create a binary regression model, transforming our adjusted margin into a simple binary choice: 0 equals a loss of money, 1 equals a profit.  This could be thought of as a "Go / No-Go" model.

Below we utilize the binomial logistic regression function in R to create the "Go / No-Go" model.

  
```{r,echo=FALSE}
# Now we're ready to explore model building. In preparation, split the dataset into a training set
# and a test set
## 80% of the sample size
#Creating a binomial column 
movies_bin <- Filter(is.numeric, movies)
movies_bin$money <- 0 
movies_bin$money[movies_bin$adj_margin > 0] <-1
pred_col <- c(1,2,3,4,5,7,8,9,11,17)
movies_bin <- movies_bin[,pred_col]

set.seed(121)
smp_size <- floor(0.80 * nrow(movies_bin))
## set the seed to make your partition reproductible
train_ind <- sample(seq_len(nrow(movies_bin)), size = smp_size)
train <- movies_bin[train_ind, ]
test <- movies_bin[-train_ind, ]
```  


```{r,echo=FALSE}
#Creating the Binomial Model 
bin_movie <- glm(money ~ ., family=binomial(link='logit'),data=train)
summary(bin_movie)

```
```{r,echo=FALSE}
pred_col <- c(1,2,3,4,5,7,8,9,11)
p <- predict(bin_movie, newdata=test, type = "response")
pr <- prediction(p, test$money)
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc 
```


Using all the prediction variables at hand, the "Go / No-Go" model accurately predicts profitability 74% of the time.  

Next, using backward stepwise regression, we attempt to remove some variables that may not have significance in our model.

```{r,echo=FALSE}
backward <- step(bin_movie)
summary(backward)

p <- predict(backward, newdata=test, type="response")
pr <- prediction(p, test$money)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
auc_back <- performance(pr, measure = "auc")
auc_back <- auc_back@y.values[[1]]
plot(prf)
abline(a = 0, b = 1)
auc_back
```

As you can see, using backward stepwise regression produces slightly better AIC scores.  However, the AUC decreases slightly, which is undesirable.  Another revelation is that the Director Facebook Likes score is not a significant variable in our model, and is thus removed by the backward stepwise regression process.  It appears that for our purposes here, the actors' Facebook Likes are better indicators of profitability than Directors', which goes to show how the industry has unfolded.  A few directors have become prominent in our culture, but the recognizability of actors and actresses determines more strongly whether or not a movie will make money.   

As a final step, we use a confusion matrix to show the relative strength of our model.

```{r, echo=FALSE}
#Creating confusion matrix
bin_prediction <- ifelse(p > 0.5, 1, 0)
confusion_bin <- confusionMatrix(data = bin_prediction, reference = test[,10])
confusion_bin$table
```

As you can see we tend to have more false negatives than false positives, and the break down of accuracy, specificity, precision and F1-score can be seen below:

```{r, echo= FALSE}
f1 <- function(s,p) {
  (2*p*s)/(p+s)
}

Parameters <- c("Accuracy", "Classification Error Rate", "Precision", "Sensitivity", "Specificity", "F1 Score")

#Creating Confusion Matrix outputs
Model1 <- c(confusion_bin$overall["Accuracy"], 1 - confusion_bin$overall["Accuracy"], confusion_bin$byClass["Pos Pred Value"], confusion_bin$byClass["Sensitivity"], confusion_bin$byClass["Specificity"], f1(confusion_bin$byClass["Sensitivity"],confusion_bin$byClass["Pos Pred Value"]))
kable(data.frame(Parameters, Model1))
```


--------


###Gross Margin Model

We now have a prediction model for whether a particular movie will make money or not.  However, from a movie investor's perspective, that information is not sufficient to make a decision about which movie is the most attractive to fund when faced with multiple options.  Therefore, another focus of our final project is to build a model that attempts to predict how much money a movie will make (Gross Margin). 

Below we build a multivariable linear regression model for Gross Margin, without any data transformation. 

```{r,echo=FALSE}
#Extract all numerical variables. Take care of na and excessive zeros.  
movies1 <- Filter(is.numeric, movies)
colSums(sapply(movies1, is.na))
colSums(sapply(movies1, function(x) return (x == 0)))

#Eliminate title_year, gross, facenumber_in_poster(too many zeros), budget, cpi
movies1 <- subset(movies1, select = -c(1, 6, 9, 10, 13))
```


Our first attempt at a Gross Margin model does not show good performance. The AIC is 121904.1, BIC is 121970.4 and  logLik is -60941.1. After we take a look at the histogram of the residuals plot, we realize it is highly skewed to the right. The skewness is as high as 13.7.  

```{r,echo=FALSE}
#Also exclude adj_margin when building the model, because it is simply the linear combinations of the other two variables, adj_gross and adj_budget.
m1 <- lm(adj_gross ~. - adj_margin, data = movies1) 
m1_back <- step(m1, trace = 0)

summary(m1_back)
glance(m1_back)
par(mfcol=c(2,2))
plot(m1_back)

hist(m1_back$residuals, main=NA, xlab = "m1_back Residuals", ylab = "Number of Movies")
skewness(m1_back$residuals)
```


The weak performance is most likely due to the abnormal skewness and kurtosis from the original data. Therefore, we attempt to correct the problem by employing Box-Cox transformation.  

```{r,echo=FALSE}
duration_bc <- boxcox(movies1$duration ~ 1, plotit = FALSE)  
duration_lambda <- with(duration_bc, x[which.max(y)])
dfl_bc <- boxcox(movies1$director_facebook_likes ~ 1, plotit = FALSE)	
dfl_lambda <- with(dfl_bc, x[which.max(y)])
a3fl_bc <- boxcox(movies1$actor_3_facebook_likes ~ 1, plotit = FALSE)	
a3fl_lambda <- with(a3fl_bc, x[which.max(y)])
a1fl_bc <- boxcox(movies1$actor_1_facebook_likes ~ 1, plotit = FALSE)	
a1fl_lambda <- with(a1fl_bc, x[which.max(y)])
nvu_bc <- boxcox(movies1$num_voted_users ~ 1, plotit = FALSE)	
nvu_lambda <- with(nvu_bc, x[which.max(y)])
ctfl_bc <- boxcox(movies1$cast_total_facebook_likes ~ 1, plotit = FALSE)	
ctfl_lambda <- with(ctfl_bc, x[which.max(y)])
a2fl_bc <- boxcox(movies1$actor_2_facebook_likes ~ 1, plotit = FALSE)	
a2fl_lambda <- with(a2fl_bc, x[which.max(y)])
imdb_bc <- boxcox((movies1$imdb_score) ~ 1, plotit = FALSE)	
imdb_lambda <- with(imdb_bc, x[which.max(y)])
ab_bc <- boxcox(movies1$adj_budget ~ 1, plotit = FALSE)	
ab_lambda <- with(ab_bc, x[which.max(y)])


duration <- BoxCox(movies1$duration, duration_lambda)
director_facebook_likes <- BoxCox(movies1$director_facebook_likes, dfl_lambda)
actor_3_facebook_likes <- BoxCox(movies1$actor_3_facebook_likes, a3fl_lambda)
actor_1_facebook_likes <- BoxCox(movies1$actor_1_facebook_likes, a1fl_lambda)
num_voted_users <- BoxCox(movies1$num_voted_users, nvu_lambda)
cast_total_facebook_likes <- BoxCox(movies1$cast_total_facebook_likes, ctfl_lambda)
actor_2_facebook_likes <- BoxCox(movies1$actor_2_facebook_likes, a2fl_lambda)
imdb_score <- BoxCox(movies1$imdb_score, imdb_lambda)
adj_budget <- BoxCox(movies1$adj_budget, ab_lambda)

movies2 <- data.frame(duration, director_facebook_likes, actor_3_facebook_likes, actor_1_facebook_likes, num_voted_users, cast_total_facebook_likes, actor_2_facebook_likes, imdb_score, adj_budget)
```


The following compares distributions of the two datasets. The first is the dataset before transformation; the second, after.  

*Before Transformation:*  

```{r,echo=FALSE}
par(mar = rep(2, 4), mfrow = c(3, 4))
for (i in 1:length(movies1))
{
    plot(density(movies1[, i]), main = colnames(movies1)[i])
}
```
  
  
*After transformation:*  


```{r,echo=FALSE}
par(mar = rep(2, 4), mfrow = c(3, 4))
for (i in 1:length(movies2))
{
    plot(density(movies2[, i]), main = colnames(movies2)[i])
}
```

From this comparison we can observe that the Box-Cox transformation approximately normalizes the data, so we proceed.  

Our second attempt at the Gross Margin model has very similar AIC, BIC, and loglikelihood values as the first.  However, the skewness of the residual histogram is reduced.  Therefore, the second attempt is a superior model.    


```{r,echo=FALSE}
movies2 <- cbind(movies2, movies1$adj_gross)
colnames(movies2)[10] <- "adj_gross"
m2 <- lm(adj_gross ~ ., data = movies2) 
m2_back <- step(m2, trace = 0)

summary(m2_back)
glance(m2_back)
par(mfcol=c(2,2))
plot(m2_back)

hist(m2_back$residuals, main=NA, xlab = "m2_back Residuals", ylab = "Number of Movies")
skewness(m2_back$residuals)
```


We apply the corrected values to our model.  Finally, we create a master dataframe containing our predicted results and actual data.  


```{r,echo=FALSE}
#Add new variable profit_margin to the original movie datasets. According to investopedia, profit_margin =  net profit / revenue. For the purpose of simplisity, here we use adjusted margin to be our net profit and adjusted gross to be our revenue
movies$profit_margin <- movies$adj_margin / movies$adj_gross


#Replace the variables with the variables obtained from Box-Cox transformation
movies_copy <- movies
movies_copy$duration <- duration
movies_copy$director_facebook_likes <- director_facebook_likes
movies_copy$actor_3_facebook_likes <- actor_3_facebook_likes
movies_copy$actor_1_facebook_likes <- actor_1_facebook_likes
movies_copy$num_voted_users <- num_voted_users
movies_copy$cast_total_facebook_likes <- cast_total_facebook_likes
movies_copy$actor_2_facebook_likes <- actor_2_facebook_likes
movies_copy$imdb_score <- imdb_score
movies_copy$adj_budget <- adj_budget


#Predicted gross
gross_p <- predict(m2_back, newdata = movies_copy, type = "response")


#Calculate predicted profit margin
profit_margin_p <- (gross_p - movies$adj_budget) / gross_p


#Creating master data frame.
movies_profit <- data.frame(movies$movie_title, movies$adj_gross, gross_p, movies$profit_margin, profit_margin_p)
colnames(movies_profit) <- c("Movie Title", "Actual Adjusted Gross", "Predicted Gross", "Actual Profit Margin", "Predicted Profit Margin")
```


Final output of Gross Margin model:  

```{r,echo=FALSE}
head(movies_profit)
```


The predicted profit margin variable can serve as a reference for investors to decide if they want to contribute to the production of a movie and share the profit that is generated.  

Since we have the actual profit margin variable available to us, we can also investigate if the quality of the movie will have any impact on the profitability of the movie. We use the IMDB rating as an analog for movie quality.  

```{r,echo=FALSE}
cor.test(movies$imdb_score, movies$profit_margin, conf.level = 0.95)
```

The result above suggests only a weak positive relationship between the quality and profitability of movies.  The p-value is 0.007905, which is less than the significance level of 0.05. In addition, the 95% confidence interval is (0.01263244, 0.08354498), which does not cross zero.  It also shows the result is statistically significant.  However, the correlation coefficient is only 0.048 (about 5% higher profit), which is a weak association between the two variables. 

Therefore, if investors care more about profitability, it is recommended not to care too much about the quality of the movie. Spending huge amounts of money on improving movie quality may lead to minuscule returns.


--------


###Plot Keywords

The Kaggle dataset includes a nefarious-looking collection of plot keywords for each movie.  We could not resist exploring them.  

To do so required some manual cleanup of typo's, duplicates, and the addition of a small amount of information from Ian Cavalier's Filmometer, as well as IMDB's Parent's Guide.  We also have an additional variable called Movie Scale, which categorizes each movie into one of four groups:

```
Movie Scale -|- CPI-Adjusted Budget
-------------|------------------------------
Tiny         |  Less than 5 million
Small        |  Between 5 and 25 million
Medium       |  Above 25, Below 100 million
Large        |  100 million and above
-------------|------------------------------
```

```{r, echo=FALSE}

movies.US.raw <- read.csv(text=getURL("https://raw.githubusercontent.com/jeffreyburmood/data621/final_rob1/movies_US.csv"),header=TRUE,na.strings=c(""," "), stringsAsFactors = FALSE)

movies.US <- na.omit(movies.US.raw)
movies.US$movie_title <- iconv(movies.US$movie_title, "latin1", "ASCII", sub="")

movies.US$content_rating <- factor(movies.US$content_rating)
movies.US$movie_scale <- factor(movies.US$movie_scale)
movies.US$nudity <- factor(movies.US$nudity)


set.seed(121)
smp_size <- floor(0.80 * nrow(movies.US))
## set the seed to make your partition reproductible
train_ind <- sample(seq_len(nrow(movies.US)), size = smp_size)
train.US <- movies.US[train_ind, ]
test.US <- movies.US[-train_ind, ]


#split the movies into four groups, based on the production budget
tiny.US <- subset(train.US, movie_scale == 'tiny')
small.US <- subset(train.US, movie_scale == 'small')
medium.US <- subset(train.US, movie_scale == 'medium')
large.US <- subset(train.US, movie_scale == 'large')


```


To get some idea of where to start looking, we use a free online tool called TagCrowd to paint word clouds of movie genre and keywords by movie scale:


![](https://raw.githubusercontent.com/jeffreyburmood/data621/master/Final/movie_keywords.png)


Tiny movie genres and keywords are shown top left, followed by small films to the right.  Medium and large films are in the bottom two blocks.
Within each block, successfilm film genres and keywords are shown on top, and unsuccessful ones below.

There are many questions one could ask about this information.  Some examples:

1. For tiny-budget films, do male-oriented crime films with graphic sex and violence perform better at the box office than films about female relationships?  
2. For large films, does escapism trump realism?
3. Is there a limited U.S. audience for films with nudity?  This seems to be the opposite of "sex sells." 

Since nudity is a kind of fun and perhaps taboo topic that weaker souls than us would carefully avoid writing about in a graduate student paper on regression analysis, let's tackle question 3.  


We split each budget category into two groups - movies with nudity and movies without. (Note: Some external sources were used to scrub the quality of the keywords for this variable).  

Our variable "Gross Over Budget" is the adjusted gross receipts of the movie (U.S. Box Office only) divided by the adjusted production budget.  While this is not an indicator of the true profitability of the movie because it doesn't include foreign screenings, DVD sales, etc, it does help provide a rough proportional gross margin percentage.  

*Movies without nudity: (V1 = Gross Over Budget)*

```{r,echo=FALSE}


#Lets look at the potential commercial impact of nudity across the four budget categories
nud.US <- subset(train.US, nudity == 'y')
dress.US <- subset(train.US, nudity == 'n')  #ASSIST from http://iancavalier.com/filmometer/reviews/genre/sexual


library(data.table)
# to Compare the profitability of movies without nudity...
dtd <- data.table(dress.US)
setkey(dtd,movie_scale)
dtd[,mean(gross_over_budget),by=movie_scale]
```

*Counts:*

```{r, echo=FALSE}
dtd[,length(gross_over_budget),by=movie_scale]

```


*Movies with nudity: (V1 = Gross Over Budget)*

```{r, echo=FALSE}
#...to movies with nudity:
dtn <- data.table(nud.US)
setkey(dtn,movie_scale)
dtn[,mean(gross_over_budget),by=movie_scale]
```

*Counts:*

```{r, echo=FALSE}

dtn[,length(gross_over_budget),by=movie_scale]

```


We can see a kind of auto-filtering going on here in the industry.  Only nine large movies include nudity, while 337 do not!  98% of large films avoid nudity at all costs.  Among medium budget films, only about 7% include nudity, and about 11% of small and tiny films do.  

Furthermore, we can see that the average gross margin percents are lower for all categories of movies with nudity, except small budget. Among large and medium films, the difference is about 16%! Tantalizing...

We create some linear regression models to determine if these results are significant:  


```{r, echo=FALSE}


#Let's create models to see if the differences are significant.
 
mtiny <- lm(gross_over_budget ~ content_rating + imdb_score + num_critic_for_reviews + num_user_for_reviews +nudity, tiny.US)
summary(mtiny)

msmall <- lm(gross_over_budget ~ content_rating + imdb_score + num_critic_for_reviews + num_user_for_reviews +nudity, small.US)
summary(msmall)

mmedium <- lm(gross_over_budget ~ content_rating + imdb_score + num_critic_for_reviews + num_user_for_reviews +nudity, medium.US)
summary(mmedium)

mlarge <- lm(gross_over_budget ~ content_rating + imdb_score + num_critic_for_reviews + num_user_for_reviews +nudity, large.US)
summary(mlarge)

```


According to the models, there is no statistical significance to the variable Nudity at any of the budget sizes!  


Of the factors considered, for tiny and small budget movies, the number of user reviews is the most significant and helpful variable for profitability.  For medium and large budget films, the number of user reviews remains important but the IMDB score enters the picture as far more impacting.  


It would be interesting to find out why the IMDB score is not significant for tiny and small movies, but it is very significant for 
medium and large movies.


The lesson learned is simple - just because the average value of one group is different from another does not mean there is a significant difference between them.  In this case, the sample size may be too low.  If time permitted, more sophisticated techniques, such as zero-inflated models, could be deployed.  


--------


Concluding Thoughts:  


There are many companies doing very sophisticated analysis to assess the viability of potential movie projects.  One is called The Numbers.  It uses a data source called Opus Data.  The models are very intricate.   

It is impossible to create competitive models with a sample dataset like ours, but it is also kind of amazing that we were able to create a "Go No/Go" model with 74% accuracy, and a robust framework for predicting gross margin percentage for a given movie.  We also had a little fun illustrating the dangers of using simple averages to prove a point, rather than robust modeling.  We hope you learned some new things about the movie business and had fun doing so!


--------


Smooth Operators - All Done!  