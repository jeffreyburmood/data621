---
title: "DATA621-FinalProject-SmoothOperators"
author: "Rob Hodde, Matt Farris, Jeffrey Burmood, Bin Lin"
date: "5/11/2017"
output: pdf_document
---

##Problem Description  
  
Our final project will explore, analyze and model a data set containing information on approximately 5,000 movies. The dataset contains movie data extracted from the IMDB website and is available on Kaggle.com.

The project will develop predictive models for two questions:  
  
1) Will the movie make money, lose money, or break even (approximately)?  
  
2) What is the anticipated gross margin (profit) for the movie?  


\begin{center}
{\huge Data Exploration}
\end{center}
  
##Data Exploration
  
```{r,echo=FALSE}
# Load required libraries

suppressWarnings(suppressMessages(library(ggplot2)))
suppressWarnings(suppressMessages(library(ROCR)))
suppressWarnings(suppressMessages(library(RCurl)))
suppressWarnings(suppressMessages(library(knitr)))
suppressWarnings(suppressMessages(library(Hmisc)))
suppressWarnings(suppressMessages(library(caret)))
suppressWarnings(suppressMessages(library(stringr)))
suppressWarnings(suppressMessages(library(mice)))
suppressWarnings(suppressMessages(library(dplyr)))
suppressWarnings(suppressMessages(library(reshape2)))
suppressWarnings(suppressMessages(library(MASS)))
suppressWarnings(suppressMessages(library(pscl)))
suppressWarnings(suppressMessages(library(broom)))
suppressWarnings(suppressMessages(library(lmtest)))
suppressWarnings(suppressMessages(library(moments)))
suppressWarnings(suppressMessages(library(forecast)))


# Read in the dataset from github
movies.raw <- read.csv(text=getURL("https://raw.githubusercontent.com/jeffreyburmood/data621/master/Final/movie_metadata.csv"),header=TRUE,na.strings=c(""," "), stringsAsFactors = FALSE)

cpi <- read.csv(text=getURL("https://raw.githubusercontent.com/jeffreyburmood/data621/master/Final/CPI-Year.csv"),header=TRUE,na.strings=c(""," "), stringsAsFactors = FALSE)
names(cpi)<-c("title_year","cpi")

# Remove the columns not being used in the analysis
col.remove <- c(1,2,3,7,10,11,15,17,18,19,20,21,27,28)
movies <- subset(movies.raw,select=-col.remove)

# there are only a few NAs, go ahead and remove rows with NAs
movies <- na.omit(movies)

movies$movie_title <- iconv(movies$movie_title, "latin1", "ASCII", sub="")
```
  
To this point we've removed the data columns for the variables that we will not be using in the analysis. The columns remaining in the data set are the following:  
  
```{r,echo=FALSE}
names(movies)
```
  
After exploring the data, we noticed there is a scattering of NAs across the variables. Due to the relatively low number of total NAs, we choose to remove all rows with NAs, leaving 3,828 rows of data.  
  
Next we will explore the nature of the data for the variables we will be using in the analysis.  
  
```{r,echo=FALSE,fig.width = 8, fig.height = 3}
# Let's start by exploring the type of each variable
types <- sapply(1:length(movies),function(x) typeof(movies[,x]))
types.df <- data.frame(VAR=names(movies),TYPE=types)
kable(types.df)

# Set up content rating as factors to form a categorical variable for modeling
movies$content_rating <- factor(movies$content_rating)

# Show a statistical summary of the data
summary(movies)

# grab just the numeric data columns for variable analysis
movies.numeric <- subset(movies,select=-c(6,10,24))

# start by looking for correlations between the numeric variables (ONLY the predictor variables)
movies.pred <- subset(movies.numeric, select=-c(5))
cor.table <- cor(movies.pred) # build a table of inter-variable correlation values
kable(cor.table[,1:4])
kable(cor.table[,5:8])
kable(cor.table[,9:10])

# Look at the boxplots of the numeric variables
f <- colnames(movies.numeric)  # establish the data categories to be studied
par(mfrow=c(1,2))

for (i in 1:length(f)){
  boxplot(movies.numeric[,i],main = f[i])
}

# we also need to look at the histograms for the numeric variables
for (i in 1:length(f)){
  m <- mean(movies.numeric[,i])
  s <- sd(movies.numeric[,i])  
  hist(movies.numeric[,i],freq=FALSE,main = f[i],xlab="")
  curve(dnorm(x,mean=m,sd=s),col="darkblue",lwd=2,add=TRUE)
}

# let's also look at a quick plot of the data for each variable
for (i in 1:length(f)){
  plot(movies.numeric[,i],main = f[i],xlab="",ylab="")
}
```
  
As we can see from the plots and statistical summary, most of the variables have a reasonable distribution except those variable associated with the Facebook likes. There are five variables related to Facebook likes that are highly skewed due to a large number of zeros. At this point we assume these zeros represent NAs in the Facebook data.  
  
Next, we'll use the mice package to impute the Facebook likes data for the zeros/NAs.
  
```{r,echo=FALSE}
# build a dataframe of just the facebook likes data
facebook.likes <- data.frame(director_facebook_likes=movies$director_facebook_likes,actor_1_facebook_likes=movies$actor_1_facebook_likes,actor_2_facebook_likes=movies$actor_2_facebook_likes,actor_3_facebook_likes=movies$actor_3_facebook_likes,cast_total_facebook_likes=movies$cast_total_facebook_likes)
# now convert all of the zero values to "NA"
facebook.likes <- sapply(facebook.likes, function(x) ifelse(x==0,NA,x))
# review the NA patterns for each variable
md.pattern(facebook.likes)
#mice PACKAGE
#uses Predictive Mean Matching. 
fb.likes.i <- mice(facebook.likes, m = 3, print=F)
facebook.likes <- complete(fb.likes.i,1)
# repopulate the movies dataframe with the imputed variable
movies$director_facebook_likes <- facebook.likes$director_facebook_likes
movies$actor_1_facebook_likes <- facebook.likes$actor_1_facebook_likes
movies$actor_2_facebook_likes <- facebook.likes$actor_2_facebook_likes
movies$actor_3_facebook_likes <- facebook.likes$actor_3_facebook_likes
movies$cast_total_facebook_likes <- facebook.likes$cast_total_facebook_likes

summary(movies)
```


\begin{center}
{\huge Data Preparation}
\end{center}


##Data Preparation  

One of the big issues faced in when using this dataset is the time frame. These movies were collected over the past 80+ years, and the following shows are distribution over time: 

```{r,echo=FALSE}
hist(movies$title_year,main = "Year Released",xlab="")
```
  

As you can see, the vast majority came from 1990s and above, but we can't discredit the movies from previous year. In order to accurately portray elements from the past, we have instituted a rate of inflation calculation. Using the consumer price index (for our part here we are making a crucial assumption, that all dollars are calculated based on US currency, and we are ignoring even more complex foreign exchange rates of the time), we can calculate the gross value per year. As a basis of comparison, we are using the CPI index from 2016, as the last movie was made in 2016. 


```{r}
movies <- merge(x = movies, y = cpi, by = "title_year")
movies$adj_gross <- with(movies, (240/cpi * gross))
movies$adj_budget <- with(movies, (240/cpi * budget))
movies$adj_margin <- with(movies, adj_gross-adj_budget)
```

```{r}
attach(movies)
plot(title_year,gross)
plot(title_year,adj_gross)
```

From the above graphs, we can see that the adjustment for the gross did indeed create a more uniformed dataset (where as before we saw movies increasing over the years). As a point of interest, the movies that made over a billion dollars are shown below:
```{r}
highest_gross <- subset(movies, adj_gross > 1000000000, select=c("movie_title", "gross", "adj_gross"))
highest_gross
```

```{r}
boxplot(movies$adj_margin)
```


\begin{center}
{\huge Build Models}
\end{center}
##Build Models  
  
```{r,echo=FALSE}
# Now we're ready to explore model building. In preparation, split the dataset into a training set
# and a test set
## 80% of the sample size
set.seed(121)
smp_size <- floor(0.80 * nrow(movies))
## set the seed to make your partition reproductible
train_ind <- sample(seq_len(nrow(movies)), size = smp_size)
train <- movies[train_ind, ]
test <- movies[-train_ind, ]
```  



###Profit Margin Model




```{r}
movies1 <- Filter(is.numeric, movies)
colSums(sapply(movies1, is.na))
colSums(sapply(movies1, function(x) return (x == 0)))

#Elminate title_year, gross, facenumber_in_poster(too many zeros), budget, cpi
movies1 <- subset(movies1, select = -c(1, 6, 9, 10, 13))
```



```{r}
##Also exclude adj_margin when building models for gross prediction, because they are simply the linear combinations of the other two variables, adj_gross and adj_budget. 
m1 <- lm(adj_gross ~. - adj_margin, data = movies1) 
m1_back <- step(m1, trace = 0)
summary(m1_back)

AIC(m1_back)
logLik(m1_back)
par(mfcol=c(2,2))
plot(m1_back)

par(mar = rep(4, 4), mfcol=c(1,2))
hist(movies1$adj_gross, xlab = "Actual Gross", ylab = "Number of Movies")
hist(fitted(m1_back), xlab = "Predicted Gross", ylab = "Number of Movies")

hist(m1_back$residuals)
skewness(m1_back$residuals)
```


```{r}
duration_bc <- boxcox(movies1$duration ~ 1, plotit = FALSE)	
duration_lambda <- with(duration_bc, x[which.max(y)])
dfl_bc <- boxcox(movies1$director_facebook_likes ~ 1, plotit = FALSE)	
dfl_lambda <- with(dfl_bc, x[which.max(y)])
a3fl_bc <- boxcox(movies1$actor_3_facebook_likes ~ 1, plotit = FALSE)	
a3fl_lambda <- with(a3fl_bc, x[which.max(y)])
a1fl_bc <- boxcox(movies1$actor_1_facebook_likes ~ 1, plotit = FALSE)	
a1fl_lambda <- with(a1fl_bc, x[which.max(y)])
nvu_bc <- boxcox(movies1$num_voted_users ~ 1, plotit = FALSE)	
nvu_lambda <- with(nvu_bc, x[which.max(y)])
ctfl_bc <- boxcox(movies1$cast_total_facebook_likes ~ 1, plotit = FALSE)	
ctfl_lambda <- with(ctfl_bc, x[which.max(y)])
a2fl_bc <- boxcox(movies1$actor_2_facebook_likes ~ 1, plotit = FALSE)	
a2fl_lambda <- with(a2fl_bc, x[which.max(y)])
imdb_bc <- boxcox((movies1$imdb_score) ~ 1, plotit = FALSE)	
imdb_lambda <- with(imdb_bc, x[which.max(y)])
ab_bc <- boxcox(movies1$adj_budget ~ 1, plotit = FALSE)	
ab_lambda <- with(ab_bc, x[which.max(y)])


duration <- BoxCox(movies1$duration, duration_lambda)
director_facebook_likes <- BoxCox(movies1$director_facebook_likes, dfl_lambda)
actor_3_facebook_likes <- BoxCox(movies1$actor_3_facebook_likes, a3fl_lambda)
actor_1_facebook_likes <- BoxCox(movies1$actor_1_facebook_likes, a1fl_lambda)
num_voted_users <- BoxCox(movies1$num_voted_users, nvu_lambda)
cast_total_facebook_likes <- BoxCox(movies1$cast_total_facebook_likes, ctfl_lambda)
actor_2_facebook_likes <- BoxCox(movies1$actor_2_facebook_likes, a2fl_lambda)
imdb_score <- BoxCox(movies1$imdb_score, imdb_lambda)
adj_budget <- BoxCox(movies1$adj_budget, ab_lambda)

movies2 <- data.frame(duration, director_facebook_likes, actor_3_facebook_likes, actor_1_facebook_likes, num_voted_users, cast_total_facebook_likes, actor_2_facebook_likes, imdb_score, adj_budget)
```


```{r}
par(mar = rep(2, 4), mfrow = c(3, 4))
for (i in 1:length(movies1))
{
    plot(density(movies1[, i]), main = colnames(movies1)[i])
}

par(mar = rep(2, 4), mfrow = c(3, 4))
for (i in 1:length(movies2))
{
    plot(density(movies2[, i]), main = colnames(movies2)[i])
}
```


```{r}
movies2 <- cbind(movies2, movies1$adj_gross)
colnames(movies2)[10] <- "adj_gross"
m2 <- lm(adj_gross ~ ., data = movies2) 
m2_back <- step(m2, trace = 0)

summary(m2_back)

par(mfcol=c(2,2))
plot(m2_back)

AIC(m2_back)
logLik(m2_back)
par(mar = rep(4, 4), mfcol=c(1,2))


hist(movies2$adj_gross, xlab = "Actual Gross", ylab = "Number of Movies", xlim=c(0, 5E8))
hist(fitted(m2_back), xlab = "Predicted Gross", ylab = "Number of Movies")

hist(m2_back$residuals)
skewness(m2_back$residuals)
```


```{r}
movies$profit_margin <- movies$adj_margin / movies$adj_gross
movies_copy <- movies
movies_copy$duration <- duration
movies_copy$director_facebook_likes <- director_facebook_likes
movies_copy$actor_3_facebook_likes <- actor_3_facebook_likes
movies_copy$actor_1_facebook_likes <- actor_1_facebook_likes
movies_copy$num_voted_users <- num_voted_users
movies_copy$cast_total_facebook_likes <- cast_total_facebook_likes
movies_copy$actor_2_facebook_likes <- actor_2_facebook_likes
movies_copy$imdb_score <- imdb_score
movies_copy$adj_budget <- adj_budget

gross_p <- predict(m2_back, newdata = movies_copy, type = "response")

#movies$profit_margin <- (movies$adj_gross - movies$adj_budget) / movies$adj_gross
profit_margin_p <- (gross_p - movies$adj_budget) / gross_p

movies_profit <- data.frame(movies$movie_title, movies$adj_gross, gross_p, movies$profit_margin, profit_margin_p)


colnames(movies_profit) <- c("Movie Title", "Actual Adjusted Gross", "Predicted Gross", "Actual Profit Margin", "Predicted Profit Margin")

head(movies_profit)
```


This line of code just to prove that, there is no correlation between the quality of the moview with 
```{r}
cor.test(movies$imdb_score, movies$profit_margin, conf.level = 0.95)
```

Smooth Operators - All Done!  
